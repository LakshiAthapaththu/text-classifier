{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from keras.layers import Input, Embedding, Dot, Reshape, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "import numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TrainingCorpus.csv\")\n",
    "testset = pd.read_csv(\"testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['අලුත් ගිණුමක් විවෘත කරන්න ඕන ' 'මට නව ගිණුමක් විවෘත කරන්න ඕන '\n",
      " 'මට නව ගිණුමක් ' 'මට නව ගිණුමක් විවෘත කරන්න ' 'ඕන ']\n"
     ]
    }
   ],
   "source": [
    "corpus = numpy.array(list(data.utter))\n",
    "#print (corpus)\n",
    "labels = numpy.array(list(data.intent))\n",
    "# print ((labels))\n",
    "\n",
    "test = numpy.array(list(testset.utter))\n",
    "y_test = numpy.array(list(testset.intent))\n",
    "\n",
    "print(test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 96\n",
    "encoded_corpus = [one_hot(word, vocab_size) for word in corpus]\n",
    "#print(encoded_corpus)\n",
    "max_len = len(max(encoded_corpus, key=len))\n",
    "print(max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 95 65 ... 70  0  0]\n",
      " [11  5 65 ... 70  0  0]\n",
      " [ 5 65 89 ...  0  0  0]\n",
      " ...\n",
      " [72  0  0 ...  0  0  0]\n",
      " [93 72 33 ...  0  0  0]\n",
      " [72 93 10 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 8\n",
    "padded_docs = pad_sequences(encoded_corpus, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 75. 22. 50. 11. 16.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word_array = []\n",
    "s = numpy.zeros([int(len(corpus)),int(max_len)])\n",
    "\n",
    "for sentence in corpus:\n",
    "    word_array.extend(sentence.split())\n",
    "    \n",
    "word_array = (set(word_array))\n",
    "word_array= list(word_array)\n",
    "#print(len(word_array))\n",
    "\n",
    "for i in range(0,len(corpus)):\n",
    "    splitted_sentence = corpus[i].split()\n",
    "    for j in range(0,len(splitted_sentence)):\n",
    "        \n",
    "        s[i,j] = word_array.index(splitted_sentence[j])+1\n",
    "print(s[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c0c3a3abbe6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(sen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mword_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "testsetdemo = []\n",
    "labels_for_test = []\n",
    "#y_test\n",
    "\n",
    "for se in range(0,len(test)):\n",
    "    #print(sen)\n",
    "    word_in = 1\n",
    "    words = test[se].split()\n",
    "    for word in words:\n",
    "        if not(word in word_array):\n",
    "            word_in = 0\n",
    "            \n",
    "    if(word_in == 1 and len(words)<9):\n",
    "        testsetdemo.append(test[se])\n",
    "        labels_for_test.append(y_test[se])\n",
    "        \n",
    "print(test[0])\n",
    "print(test[1])\n",
    "print(test[2])\n",
    "print(test[3])\n",
    "testsetdemo = numpy.array(testsetdemo) \n",
    "print(len(testsetdemo))\n",
    "print(len(labels_for_test))\n",
    "max_len_2 = len(max(encoded_corpus, key=len))\n",
    "\n",
    "    \n",
    "s_test = numpy.zeros([len(testsetdemo),int(max_len)])\n",
    "for i in range(0,len(testsetdemo)):\n",
    "    splitted_sentence = testsetdemo[i].split()\n",
    "    for j in range(0,len(splitted_sentence)):\n",
    "        \n",
    "        s_test[i,j] = word_array.index(splitted_sentence[j])+1\n",
    "print(s_test[0])\n",
    "print(s_test[1])\n",
    "print(s_test[2])\n",
    "print(s_test[3])\n",
    "#print(labels_for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 8\n",
    "# padded_docs = pad_sequences(encoded_corpus, maxlen=max_length, padding='post')\n",
    "# print(padded_docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'sentence': array([[ 5., 15., 66., ...,  0.,  0.,  0.],\n",
       "         [57.,  8., 43., ...,  0.,  0.,  0.],\n",
       "         [76.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         ...,\n",
       "         [68.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "         [51., 90., 15., ...,  0.,  0.,  0.],\n",
       "         [88., 66., 84., ...,  0.,  0.,  0.]]),\n",
       "  'intent': array([ 5., 10.,  8.,  2.,  1.,  3.,  1.,  3.,  4.,  5.,  3.,  4., 10.,\n",
       "          1.,  5., 11.,  7.,  7.,  9., 10.,  6.,  3.,  7.,  5.,  8.,  8.,\n",
       "          8.,  7.,  8.,  6., 11.,  6.,  4.,  1.,  1.,  5., 10.,  6.,  3.,\n",
       "          3.,  1.,  6.,  7.,  4.,  5.,  1.,  1.,  8.,  1.,  9.,  4.,  1.,\n",
       "          3.,  9.,  2.,  2.,  6.,  4.,  5.,  5.,  9.,  8.,  2.,  1.,  6.,\n",
       "          1.,  4.,  7.,  7.,  2.,  2.,  8.,  5.,  2.,  5.,  6.,  6.,  8.,\n",
       "          1.,  6.,  7.,  2.,  2.,  8.,  4.,  1.,  7.,  5.,  2.,  7.,  9.,\n",
       "          6., 10.,  6.,  3.,  1.,  4.,  3., 11., 11.,  4.,  7., 11., 10.,\n",
       "          8.,  1.,  2., 10.,  4.,  1., 10.,  1.,  8.,  7.,  6.,  6., 10.,\n",
       "          3.,  3., 10.,  9.,  2.,  9.,  9.,  4.,  6.,  4.,  2.,  8.,  2.,\n",
       "          6.,  1.,  2.,  6.,  9.,  5.,  9.,  4.,  3.,  9.,  7.,  5.,  1.,\n",
       "          3.,  7.,  7.,  5.,  3.,  2.,  9.,  6.,  9.,  1.,  9.,  4.,  8.,\n",
       "          1.,  3.,  1.,  2.,  9.,  1.,  6.,  9.,  1.])},\n",
       " array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1.]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_bags_for_training = []\n",
    "lables_for_training = []\n",
    "a = []\n",
    "def generate_batch(word_bags,label_bags, n_positive = 150, negative_ratio = 0.1):\n",
    "    #print(word_bags)\n",
    "    batch_size = n_positive*(1.0+negative_ratio)\n",
    "    batch_size = int(batch_size)\n",
    "    #batch = np.zeros((batch_size, 3))\n",
    "#     print(type(batch))\n",
    "#     batch[0,:] = (9,0,[7,7,8])\n",
    "#     print(batch[0])\n",
    "   \n",
    "    word_bags = (word_bags)\n",
    "    label_bags =(label_bags)\n",
    "    \n",
    "    while True:\n",
    "        batch = numpy.zeros([batch_size, 8])\n",
    "        label_array = numpy.zeros([batch_size])\n",
    "        sign_array =  numpy.zeros([batch_size])\n",
    "        \n",
    "        \n",
    "        ind = 0\n",
    "        index = []\n",
    "        while(len(index) != n_positive):\n",
    "            num = random.randrange(0,164)\n",
    "            if(num not in index):\n",
    "                index.append(num)\n",
    "\n",
    "        batch_index = 0\n",
    "        for i in index:\n",
    "             batch[batch_index] = word_bags[i]\n",
    "             label_array[batch_index] = label_bags[i]\n",
    "             sign_array[batch_index] = 1\n",
    "             batch_index+=1\n",
    "       \n",
    "\n",
    "        negatives = batch_size-n_positive\n",
    "        count = 0\n",
    "        while(count != negatives):\n",
    "            num1 = random.randrange(0, 164)\n",
    "            num2 = random.randrange(0, 164)\n",
    "            if(num1 != num2):\n",
    "                   count+=1\n",
    "                   batch[batch_index] = word_bags[num1]\n",
    "                   label_array[batch_index] = label_bags[num2]\n",
    "                   sign_array[batch_index] = -1\n",
    "                   batch_index+=1\n",
    "\n",
    "        batch = numpy.array(batch)\n",
    "        yield {'sentence': batch, 'intent': label_array}, sign_array\n",
    "\n",
    "\n",
    "# batch = generate_batch(numpy.array(padded_docs),numpy.array(labels))\n",
    "next(generate_batch(s,labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.],\n",
       "        [51., 33., 27.,  1., 29., 74.,  0.,  0.]]),\n",
       " array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_batch_predict(word):\n",
    "    while True:\n",
    "         op = numpy.zeros([11])\n",
    "         w = numpy.zeros([11,8])\n",
    "         for i in range(1,12):\n",
    "            op[i-1] = i\n",
    "            w[i-1] = word\n",
    "                \n",
    "         yield {'sentence':w,'intent':op}\n",
    "            \n",
    "next(generate_batch_test([51, 33, 27,  1, 29, 74,  0,  0,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"sentence_5:0\", shape=(?, 8), dtype=float32)\n",
      "Tensor(\"dot_product_5/MatMul:0\", shape=(?, 8, 1), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "intent (InputLayer)             (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sentence_embedding (Embedding)  (None, 8, 10)        960         sentence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "intent_embedding (Embedding)    (None, 1, 10)        120         intent[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 8, 1)         0           sentence_embedding[0][0]         \n",
      "                                                                 intent_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 8)            0           dot_product[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            9           reshape_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,089\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def word_embedding_model(embedding_size = 10, classification = False):\n",
    "    \"\"\"Model to embed books and wikilinks using the functional API.\n",
    "       Trained to discern if a link is present in a article\"\"\"\n",
    "    \n",
    "    # Both inputs are 1-dimensional\n",
    "    sentence = Input(name = 'sentence', shape = [8,])\n",
    "    intent = Input(name = 'intent', shape = [1])\n",
    "    print(sentence)\n",
    "    \n",
    "    # Embedding the book (shape will be (None, 1, 50))\n",
    "    sentence_embedding = Embedding(name = 'sentence_embedding',\n",
    "                               input_dim = 96,\n",
    "                               output_dim = embedding_size)(sentence)\n",
    "    \n",
    "    # Embedding the link (shape will be (None, 1, 50))\n",
    "    intent_embedding = Embedding(name = 'intent_embedding',\n",
    "                               input_dim = 12,\n",
    "                               output_dim = embedding_size)(intent)\n",
    "    \n",
    "    # Merge the layers with a dot product along the second axis (shape will be (None, 1, 1))\n",
    "    merged = Dot(name = 'dot_product', normalize = True, axes = 2)([sentence_embedding, intent_embedding])\n",
    "    print(merged)\n",
    "    \n",
    "#     Reshape to be a single number (shape will be (None, 1))\n",
    "    merged = Reshape(target_shape = [8])(merged)\n",
    "    \n",
    "    # If classifcation, add extra layer and loss function is binary cross entropy\n",
    "#     if classification:\n",
    "    merged = Dense(1, activation = 'sigmoid')(merged)\n",
    "    model = Model(inputs = [sentence ,intent ], outputs = merged)\n",
    "    model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    # Otherwise loss function is mean squared error\n",
    "#     else:\n",
    "#         model = Model(inputs = [book, link], outputs = merged)\n",
    "#         model.compile(optimizer = 'Adam', loss = 'mse')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate model and show parameters\n",
    "model = word_embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 0s - loss: 0.7025 - acc: 0.4081\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6784 - acc: 0.5071\n",
      "Epoch 3/20\n",
      " - 0s - loss: 0.6477 - acc: 0.6040\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.6250 - acc: 0.6828\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.6159 - acc: 0.7455\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.5916 - acc: 0.7778\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.5753 - acc: 0.8162\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.5493 - acc: 0.8222\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.5468 - acc: 0.8384\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.5390 - acc: 0.8606\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.5226 - acc: 0.8586\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.5161 - acc: 0.8646\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.5097 - acc: 0.8707\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.5063 - acc: 0.8707\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.4863 - acc: 0.8707\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.4799 - acc: 0.8747\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.4730 - acc: 0.8768\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.4775 - acc: 0.8869\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.4723 - acc: 0.8788\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.4646 - acc: 0.8909\n"
     ]
    }
   ],
   "source": [
    "gen = generate_batch(s,labels)\n",
    "#print(gen)\n",
    "#for el in gen:print(el)\n",
    "h = model.fit_generator(gen, epochs = 20, \n",
    "                        steps_per_epoch = 3,\n",
    "                        verbose = 2)\n",
    "# X = numpy.array(padded_docs)\n",
    "# Y = numpy.array(labels)\n",
    "#h = model.fit([padded_docs,labels], batch_size=75, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-947d452ff5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.evaluate(s_test,labels_for_test, batch_size=128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgen1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# gen1 = generate_batch_test(s_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# [33. 27.  1. 29. 74.  0.  0.  0.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_batch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# model.evaluate(s_test,labels_for_test, batch_size=128)\n",
    "\n",
    "gen1 = generate_batch(s_test,y_test)\n",
    "# gen1 = generate_batch_test(s_test)\n",
    "# [33. 27.  1. 29. 74.  0.  0.  0.]\n",
    "# [51. 59. 27.  1. 29. 74.  0.  0.]\n",
    "# [51. 59. 27.  0.  0.  0.  0.  0.]\n",
    "# [51. 59. 27.  1. 29.  0.  0.  0.]\n",
    "gen2 = generate_batch(s_test,y_test)\n",
    "gen3 = generate_batch_predict([51., 33., 27.,  1., 29., 74.,  0.,  0.,])\n",
    "gen4 = generate_batch_predict([51., 59., 27.,  1., 29., 74.,  0.,  0.,])\n",
    "gen5 = generate_batch_predict([51., 59., 27.,  0.,  0.,  0.,  0.,  0.,])\n",
    "gen6 = generate_batch_predict([51., 59., 27.,  1., 29.,  0.,  0.,  0.,])\n",
    "\n",
    "prediction1 = model.predict_generator(gen3,1)\n",
    "prediction2 = model.predict_generator(gen4,1)\n",
    "prediction3 = model.predict_generator(gen5,1)\n",
    "prediction4 = model.predict_generator(gen6,1)\n",
    "print((prediction1))\n",
    "print((prediction2))\n",
    "print((prediction3))\n",
    "print((prediction4))\n",
    "print(score)\n",
    "\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
